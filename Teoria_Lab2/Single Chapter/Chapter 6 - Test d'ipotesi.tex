\documentclass[11pt,a4paper]{book}
\usepackage{titlesec}
\usepackage{setspace}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{color,soul}
\usepackage[customcolors,shade]{hf-tikz}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{sidecap}

\graphicspath{{/Users/giuliodilernia/Documents/Laboratory-Notes/Teoria_Lab2/images/}}

\renewcommand{\baselinestretch}{1.3} 

\titleformat{\chapter}[display]
 {\bfseries\Large}
  {\filright\MakeUppercase{\chaptertitlename} \Huge\thechapter}
  {1ex}
  {\titlerule\vspace{1ex}\filleft}
  [\vspace{1ex}\titlerule]

\begin{document}
\setcounter{chapter}{5}
\chapter{Test d'ipotesi}

\section{Test del $\chi^2$}

Consideriamo un campione di N misure $\{(x_i,y_i)\}_i^N$ IID legate tra loro da una funzione $y =\psi(x,\vec{\theta})$ avremo che le misure campionate rispetto alla variabile aleatoria y, possono essere riscritte come $y_i = \psi(x,\vec{\theta}) + \epsilon_i$ dove $\epsilon$ ipotizziamo essere una variabile aleatoria la cui $pdf(\epsilon)$ segue una distribuzione di probabilit\`{a} Gaussiana. Nell'ipotesi in cui valga il TCL per le $\epsilon_i$, si ha che il $Q^2$ associato alle misure e il modello segue la distribuzione di $\chi^2(N-k)$.

 
\begin{figure}[ht]
\vspace{0.2in}
\includegraphics[scale = 0.35]{compa}	
\centering
\vspace{0.1in}
\caption{Due modelli differenti che interpolano lo stesso campione di dati.}
\end{figure} 
\noindent Nel caso di destra in figura 6.1 gli scarti quadratici sono minori, mentre in quello di destra sono pi\`{u} grandi, di conseguenza possiamo aspettarci che il valore di aspettazione della distribuzione di $\chi^2$ del modello di sinistra sia pi\`{u} grande di quello di destra. Definiamo il modello non corretto (quello di sinistra) $H_1$ e il modello corretto (quello di destra) $H_0$, la domanda che possiamo porci \`{e}: " Se partiamo da due ipotesi $H_1$ e $H_0$ e non sappiamo quale delle due sia corretta, come facciamo a determinare quella che descrive meglio la realt\`{a} sperimentale? ". \newline
Introduciamo una nuova quantit\`{a} definita \textbf{p-value} che ha la seguente espressione :
\vspace{0.2in}

\begin{minipage}{.4\textwidth}
	\begin{equation}
		\text{p-value} = \int_{\overline{Q}^2}^{\infty}\chi^2(N-k)d\chi^2 
	\end{equation}
  \end{minipage}
  \begin{minipage}{.4\textwidth}
    \centering
    \includegraphics[scale = 0.3]{pvalue}	
  \end{minipage}
\vspace{0.2in}

\noindent la quantit\`{a} cos\`{i} definita risulta essere una misura di probabilit\`{a}. Per rispondere alla domanda precedente fissiamo una soglia di tolleranza del p-value oltre alla quale i valori ottenuti risultano essere dei \textbf{falsi negativi}. Riprendendo i modelli $H_0$ e $H_1$ che definiamo rispettivamente \textbf{null hypothesis} e \textbf{alternative hypothesis}, fissata una soglia del p-value, e definita una statistica x associata (come per esempio il $Q^2$) al $\chi^2(x \vert N-k)$ avremo che:
\begin{itemize}
	\item H0 \`{e} rigettata se x cade nella regione in azzurro $\omega_\alpha^* $ in figura 6.2
	\item H0 \`{e} accettata se x cade nella regione in verde $\omega_\alpha$ nella figura sottostante.
\end{itemize}
\begin{figure}[ht]
\includegraphics[scale = 0.4]{hypo}	
\centering
\end{figure}
Dunque date due ipotesi $H_0$ e $H_1$ decidiamo di considerare affermativa quella che restituisce il valore del p-value pi\'{u} alto (ovvero quella con probabilit\'{a} maggiore) rispetto al valore $p_0$ di soglia considerato, apparentemente sembrerebbe sufficiente per concludere quale delle due ipotesi sia verifica, ma in realt\'{a} come si vedr\'{a} nelle sezioni succesive la realt\'{a} sperimentale \'{e} pi\'{u} complicata e posso esserci casi di falso positivi.

\noindent Su quanto discusso fino ad ora possiamo fare le seguenti osservazioni:
\begin{itemize}
	\item I minimi quadrati permettono di calcolare il $Q^2$ (e anche il metodo di ML calcola i parametri $\hat{\theta}$ da cui si può calcolare il $Q^2$);
	\item Il test del $\chi^2$ \'{e} applicabile se sappiamo calcolare il valore del $Q^2 \Rightarrow \sigma^2$  deve essere nota e ben stimata;
	\item Test del $\chi^2$ è un test integrale $\Rightarrow$ Somma gli scarti su tutti gli eventi, e dunque pu\'{o} presentare delle limitazioni (esempio sotto).
\end{itemize}

\subsubsection{Esempio}

\begin{wrapfigure}[18]{l}{0.\textwidth}
\centering
\includegraphics[scale = 0.5]{esempio}	
\end{wrapfigure}

Assumiamo che il p-value sia accettabile ovvero maggiore
dell'intervallo di confidenza. Consideriamo gli stessi punti 
riorganizzati in un modo diverso, ma con stesso scarto quadratico.
I due set di dati con y differenti hanno lo stesso p-value.

Essendo che il test del $\chi^2$ ha una forma integrale, se
graficamente si osserva una distribuzione differente delle
misure, il test non lo tiene in considerazione.

Se consideriamo una dispersione delle misure come nella terza figura e
assumiamo che abbia il medesimo p-value delle altre due, si ha
che il test non considera che i dati diminuiscono di valore lungo l'asse delle ordinate e dunque si ottiene un \textbf{falso positivo}, ovvero p-value \`{e} verificato, ma il modello non descrive adeguatamente il comportamento dei dati sperimentali.
Il fatto che il test del $\chi^2$ abbia forma integrale limita la generalit\`{a} con cui possiamo decidere se il risultato ottenuto sia affidabile o meno.
\newline
\newline
\textbf{Definizione di Overfitting}

\begin{wrapfigure}{r}{0.\textwidth}
\centering
\includegraphics[scale = 0.5]{overfit}	
\end{wrapfigure}
\vspace{0.05in}

\noindent Ipotizziamo di avere un fit che ha $Q^2$ = 0 e p-value-1,
ovvero i dati vengono interpolati perfettamente , questo non è
un buon risultato. Si ha un caso di overfitting, dove si sono introdotti così tanti parametri che
il risultato del fit si \`{e} completamente adattato alle misure, perdendo qualsiasi
capacit\`{a} di generalizzare il modello. 

\subsection{Applicazione del test di $\chi^2$}

Se il modello \`{e} corretto $y = \psi(x,\vec{\theta})$, allora il metodo dei MQ fornisce una stima dei parametri $\vec{\theta}$ che lo descrivono. Il valore stimato dei parametri rappresenta il punto di minimo del funzione di $Q^2_{min} = Q^2(x,\vec{\theta}_{MQ})$ rispetto al campione sperimentale, tale punto di minimo coincide anche con il massimo della distribuzione di $\chi^2$ se pdf($\epsilon$) seguono una distribuzione gaussiana, che \`{e} dato da $E[Q^2] = N-k$ e quindi $Q^2_{min} = N-k$. \newline
Il $\chi^2$ ridotto \`{e} definito come $\chi^2_{0} = \frac{\chi^2}{N-k}$ ci\`{o} implica che per $\chi^2 = Q^2_{min}$ il ridotto \`{e} $\chi^2_0 \sim 1$. \newline
Se il valore del $\chi^2$ \`{e} lontano dal suo valore di aspettazione N-k (o 1 nel caso si usi quello ridotto), possiamo concludere che alcune delle ipotesi precedenti non sia corrette e dunque \textbf{i dati non confermano il modello}. 

\noindent Le regioni a bassi valori di $\chi^2$ corrispondono a scarti tra modello e dati molto piccoli, quindi a casi di overfitting. Tali risultati sono altamente imporbabili. Tali risultati possono essere dovuti sovrastime degli errorri, la pdf non \'{e} Gaussiana o se le incertezze considerate non hanno solo incertezze di tipo statistico. 

\begin{figure}[ht]
\vspace{0.1in}
\includegraphics[scale =0.4]{testchi}	
\centering
\caption{Overfitting}
\end{figure}
\section{Errori di test statistici}

Quanto discusso in questa sezione fa riferimento al test del $\chi^2$, ma generalizzabile a qualsiasi statistica $\beta$ per cui \'{e} possibile definire due distribzioni di probabilit\'{a}:

\begin{itemize}
	\item $pdf(\beta \vert H_0)$ = \textbf{Null Hypothesis 
	\item $pdf(\beta \vert H_1)$ = \textbf{Alternative Hyp}othesis}
\end{itemize}
\subsection{Errori del $I^{\circ}$ tipo}

Un errore del primo tipo rappresenta il numero di casi veri per la null hypothesis Ho che scartiamo fissata una soglia del p-value.

\vspace{0.3in}
\begin{minipage}{.4\textwidth}
	\begin{equation}
		\alpha = \int_{\overline{Q}^2}^{\infty}\chi^2(N-k)d\chi^2 
	\end{equation}
  \end{minipage}
  \begin{minipage}{.4\textwidth}
    \centering
    \includegraphics[scale = 0.4]{size}	
  \end{minipage}
\vspace{0.2in}

Il termine $\alpha $ prende il nome di \textbf{size del test}. 

\subsection{Errori del $II^{\circ}$ tipo}

 Un errore del secondo tipo rappresenta la probabilit\`{a} di accettare H0 quando \`{e} vera H1, in questo caso si parla di \textbf{falsi positivi}. 
 \vspace{0.2in}
 
\begin{minipage}{.4\textwidth}
	\begin{equation}
		\beta = \int_{Q^2}^{\overline{Q}^2}\chi^2(N-k)d\chi^2 
	\end{equation}
  \end{minipage}
  \begin{minipage}{.4\textwidth}
    \centering
    \includegraphics[scale = 0.3]{powertest}	
  \end{minipage}
\vspace{0.2in}

Si sta commettendo un errore poich\`{e} se H1 \`{e} la forma funzionale sbagliata il fit dei dati supera ugualmente il test del $\chi^2$. 

\noindent Il termine $1-\beta$ prendere il nome di \textbf{power del test} e restituisce la probabilit\`{a} di rifiutare $H_0$ quando $H_1$ \`{e} vera.
\newline

\noindent Fissate le due ipotesi alternative e definiti gli intervalli di confidenza, se si assume che l'errore di tipo uno sia quello pi\`{u} grave si procede scegliendo la percentuale di falsi negativi che si reputa accettabile e si cerca di definire gli intervalli $\omega_\alpha$ e $\omega_\alpha^*$ in modo tale che $\beta$ sia il minore possibile (minor caso di falsi positivi). Il test cos\`{i} descritto viene definito il pi\`{u} potente per un determinato valore di soglia del p-value.

\section{Test di Kolgomorov-Smirnov}

Consideriamo un insieme di N misure della stessa grandezza fisica X vogliamo testare la null hypothesis $H_0$ che siano campionamenti di una determinata pdf che prendiamo come riferimento. Una possibilit\`{a} \`{e} di usare il test del $\chi^2$ applicandolo agli istogrammi costruiti con le misure raccolte e la pdf-modello. Tale procedura \`{e} corretta, ma richiedere di binnare i dati e dunque si ha una perdita d'informazione, inoltre l'esito del test pu\`{o} dipendere dal binning scelto per la costruzione degli istogrammi.

L'alternativa \`{e} data dal test di \textbf{Kolgomorv-Smirnof} che confronta le due distribuzioni cumulative (dati - pdf-modello) e in questo modo sfrutta tuta l'informazione contenuta nei dati. Tale test \`{e} di tipo non parametrico ovvero non richiede la costruzione di stimatori rispetto ai dati raccolti sperimentalmente e viene utilizzato per variabili aleatorie continue. 


\subsection{Costruzione del test}

Date N misure ordinate in senso crescente, ricostruiamo la distribuzione cumulativa della pdf-modello, definendo una funzione a gradini $S_n (x)$ rispetto ai dati del campione, tale funzione prende il nome di \textbf{EDF (Empirical Distribution Function)}, la scelta ricade su una funzione di questo tipo poich\`{e} sono presenti dei buchi nell'informazione (campione) raccolta. La forma dell'EDF \`{e} data:

\begin{equation}
	S_n(x) = \sum_{i=1}^nI(x_i \leq x)  
\end{equation}
dove la funzione $I(x_i \leq x)$ prende il nome di \textbf{indicator function} ed \'{e} espressa come:

\vspace{0.2in}

\begin{minipage}{.4\textwidth}
	\begin{align*}
I(x) = 
	\begin{cases}
	1 \quad x \leq x_{i+1} \\
	0 \quad \quad \quad \text{altrimenti}\\
	\end{cases}
\end{align*}
  \end{minipage}
  \begin{minipage}{.4\textwidth}
    \centering
    \includegraphics[scale = 0.3]{step}	
  \end{minipage}
\vspace{0.2in}

Ci si domanda quanto bene $S_n$ approssimi la cumulativa F(x), la risposta \`{e} che dipende dal numero di misure contate prima del gradino successivo e quindi da come si scelgono gli intervalli. Per valutare l'approssimazione per ogni punto distinto che costituisce un estremante degli intervalli $\tilde{x}$ valutiamo l'estremo superiore della differenza tra la EDF e la pdf con cui vogliamo confrontarla:
\begin{equation*}
	D_n = \sup_{x} \vert S_n(x) -F(x) \vert 
\end{equation*}
 la distanza $d_n \equiv \sqrt{n}D_n$ definisce il valore di riferimento per il test di KS che consiste nel confrontare tale numero con una grandezza di riferimento $d_0$, che costituisce la quantit\'{a} di soglia rispetto alla quale rigettare la null hypothesis $H_0$. Se $d > d_0$ l'ipotesi di compatibilit\`{a} viene rigettata. Il valore di $\delta_0$ \`{e} scelto in base alla probabilit\`{a} che la variabile casuale $\delta$ sia maggiore di $\delta_0$ quando il modello \`{e} corretto.
 \begin{equation*}
 	P(\delta > \delta_0 \vert H_0) = \alpha
 \end{equation*}
Tale metodo non parametrico \`{e} anche utile per confrontare due campioni di dati al fine di determinare se provengono dalla stessa popolazione. Si noti anche che la \textbf{EDF(x)} costruita \`{e} anch'essa una distribuzione cumulativa di probabilit\'{a}.
 
 \section{Confronto di una misura con il valore di riferimento}
 
 \subsection{Distribuzione t-student}
 Si consideri un campione di N misure di cui si \`{e} calcolata la media campionaria $\overline{x} = \frac{1}{N} \sum x_i$ e si supponga di conoscere $\sigma_i$ delle singole misure e $E[x] = \mu$, allora la media aritmetica $\overline{x}$ \`{e} per il TCL \`{e} distribuita come una gaussian G($\overline{x}$,$\mu$, $\frac{\sigma}{\sqrt{N}}$). Come facciamo a dire che $\overline{x}$ e ${\mu}$ sono sufficientemente vicine tra loro rispetto alle incertezze ?
 \newline
 Per determinare la distanza tra le grandezze definiamo la distribuzione t-student data dalla variabile aleatoria:
 
 \begin{equation*}
 	t = \dfrac{\vert \overline{x} - \mu\vert }{\frac{\sigma}{\sqrt{N}}}
 \end{equation*}
 definita rispetto al caso descritto nelle righe precedenti. In generale la t-student per un parametro \`{e} data da:
 \begin{equation}
 	t = \dfrac{\vert \hat{\theta}^* - \theta_t \vert}{\sigma_{\theta^*}}
 \end{equation}
 
 Notare che nel caso in cui si conoscano a priori l'incertezza della misura che si sta confrontando, dunque non si \`{e} ottenuta mediante un processo statistico si ha che la pdf(t) \'{e} Gaussiana.
 Se $\overline{x}$ segue una pdf Gaussiana e $Q^2 \sim \chi^2(N-1)$ la distibuzione di t-student ha la seguente forma funzionale.
 
 \begin{equation}
 	f(t,\nu = N-1) = \dfrac{1}{\sqrt{n\nu}} \cdot \dfrac{\Gamma({\frac{\nu+1}{2}})}{\Gamma(\frac{\nu}{2})} \cdot \Big (1 + \frac{t^2}{\nu} \Big) ^{-(\frac{\nu+1}{2})}
 \end{equation}
 
 \subsubsection{Propriet\`{a} della distribuzione}
 \begin{align*}
 	\begin{matrix}
 		\mu = E[t] = 0 & \quad \quad & \gamma_1 = 0 \\
 		\\
 		\sigma^2 = V[t] = \frac{\nu}{\nu-2} \quad \nu > 2 & \quad \quad & \gamma_2 = \frac{6}{\nu-4} \quad \nu > 4
 	\end{matrix}	
 \end{align*}
 \newline
 Per $\nu \rightarrow \infty$ la distribuzione diventa Gaussiana. Si osserva che la pdf della t-student \`{e} un po' pi\`{u} larga della distribuzione Gaussiana (fig 6.2).
 
  
\begin{figure}[ht]
\vspace{0.1in}
\includegraphics[scale = 0.4]{student}	
\centering
\vspace{0.1in}
\caption{Confronto distribuzioe di Gauss e t-student}
\end{figure}
In generale possiamo vedere la distribuzione della t-student come il rapporto tra una Gaussiana normalizzata e la radice di  $\frac{\chi^2}{N-1}$.
\begin{equation*}
	t = \dfrac{\vert \overline{x} - \mu \vert}{\Big [{\dfrac{\hat{\sigma}^2}{N}} \Big ]^{\frac{1}{2}}} = \textcolor{cyan}{\dfrac{\vert \overline{x} - \mu \vert}{\Big [{\dfrac{\sigma^2}{N}} \Big ]^{\frac{1}{2}}}} \cdot \textcolor{red}{\dfrac{\Big [ \dfrac{\sigma^2}{N} \Big]^{\frac{1}{2}}}{\Big [ \dfrac{\hat{\sigma}^2}{N} \Big]^{\frac{1}{2}}}} = \textcolor{cyan}{\dfrac{\vert \overline{x} - \mu \vert}{\Big [{\dfrac{\sigma^2}{N}} \Big ]^{\frac{1}{2}}}} \cdot \textcolor{red}{\Big [ \dfrac{\chi^2}{N-1} \Big ]^{\frac{1}{2}}}  
\end{equation*}
la parte in azzurro segue la pdf di una Gaussiana normalizzata N(0,1), mentre la parte in rosso segue $\frac{\chi^2}{N-1}$. Dove:
\begin{equation*}
	\textcolor{red}{\dfrac{1}{\Big [ \dfrac{\sigma^2}{\hat{\sigma}^2} \Big ]^{\frac{1}{2}}} = \dfrac{1}{\Big[  \frac{N-1}{\chi^2} \Big ]^{\frac{1}{2}} } = \Big [ \dfrac{\chi^2}{N-1} \Big ]^{\frac{1}{2}}  } 
\end{equation*}
Per la t-student fissato un valore di soglia $t_0$, ci permette di determinare la compatibilit\`{a} tra il valore stimato e quello atteso, se $t>t_0$ allora le due misure risultano essere non compatibili tra loro. Dove gli intervalli di compatibilit\`{a} risultano essere in multipli di deviazioni standard.
\begin{figure}[ht]
\vspace{0.1in}
\includegraphics[scale = 0.5]{Bellcurve}	
\centering
\end{figure}

\subsubsection{Confronto tra la stima di due parametri}

La distribuzione di t-student pu\`{o} essere utilizzata non solo per confrontare una misura con un valore atteso, ma anche due stime del medesimo parametro tra loro.

\begin{equation}
	z = \dfrac{\vert \theta^*_1 - \theta^*_2 \vert }{ \Big [\dfrac{\hat{\sigma_1}}{N} +\dfrac{\hat{\sigma_2}}{N} \Big ]^{\frac{1}{2}}}
\end{equation}
dove la pdf(z) \`{e} Gaussiana se $\sigma_1$ e $\sigma_2$ sono senza errore, mentre altrimenti segue una distribuzione di t-student con N-M-2 gradi di libert\`{a}.

\section{Intervalli di confidenza}

Ipotizziamo che lo stimatore $\hat{\theta}$ segue una distribuzione gaussiana G($\hat{\theta},\theta_t,\sigma$) determinato il suo valore $\theta^*$ ci domandiamo quale sia la probabilit\`{a} che tale valore disti $\sigma$ dal valore vero $\theta_t$, ovvero $P[\theta^* \in (\theta_t - \sigma, \theta_t + \sigma)]$ = 0,68. Essendo $\theta^*$ una variabile aleatoria dipendente dal campione mentre $\theta_t$ no, l'affermazione precedente non \`{e} corretta, in quanto $\theta_t$ non \`{e} una variabile aleatoria, per questo motivo riscriviamo l'intervallo di confidenza in $ \theta_t \in (\theta^* - \sigma,\theta^* + \sigma)$ e la probabilit\`{a} come $P[\theta_t \in (\theta^* - \sigma, \theta^* + \sigma)]$ = 0,68, determinando un 68 \% di confidenza nell'intercettare $\theta_t$ ripetendo l'esperimento.
\begin{figure}[ht]
\vspace{0.1in}
\includegraphics[scale = 0.45]{intervaltheta}	
\centering
\end{figure}

\subsection{Metodo della cintura di confidenza}

Definiamo uno stimatore $\hat{\theta} \equiv \hat{\theta}(x)$, di un parametro $\theta$ rispetto ad un campione di N variabili aleatorie IID di una grandezza x, poich\`{e} lo stimatore dipende da variabili aleatorie anch'esso \`{e} una r.v. di conseguenza seguir\`{a} una distribuzione di probabilit\`{a} $f(\hat{\theta} \;\vert \; \theta)$. Per ciascun campione raccolto $\hat{\theta}$ definir\`{a} una stima $\theta^*$ del parametro, costruendo la pdf associata. Ripetendo l'esperimento con diversi campionamenti ciascuna distribuzione relativa  avr\`{a} un valore atteso $E[\hat{\theta}] = \theta_{t}^{i}$ e una varianza $V[\hat{\theta}] = \sigma_{\theta_{t}^i}^2$.\newline
Per ciascun esperimento non conosciamo la forma analitica della pdf oppure non siamo in grado di definirla di conseguenza per stimare l'intervallo di confidenza di un certo valore di $\theta^*$ stimato usiamo il seguente metodo:
\newline
\begin{wrapfigure}{r}{0.\textwidth}
\centering
\includegraphics[scale = 0.4]{confidence}	
\end{wrapfigure}
$\bullet$ Per ogni valore di $\theta_{t}^i$ definiamo $pdf_i(\hat{\theta} \vert \theta_t$);\newline

\noindent $\bullet$ Si determinano i punti della pdf($\hat{\theta} \vert \theta_t$) che definiscono un intervallo di confidenza per il $\theta_t$ corrispettivo;\newline

\noindent $\bullet$ Si tracciano due rette parallele che attraversano ciascuna i punti estremanti di ciascun intervallo di confidenza, definendo una banda nel piano $(\theta_t,\theta^*)$ che prende il nome di \textbf{Confidence Band}.
\begin{figure}[ht]
\vspace{0.2in}
\includegraphics[scale = 0.4]{confidenceband}	
\centering
\caption{Banda di confidenza ed intervallo di confiedenza}
\end{figure}

\noindent Quando si effettua una misura si trova $\theta^*$ e dove tale valore interseca la confidence band, punti
d'intersezione determinano l'intervallo di confidenza di $\theta_t$. Si dimostra che l'intervallo trovato ha copertura uguale a quello scelto per le singole p.d.f.


\section{Discovery Significance}

Consideriamo di rilevare un numero di eventi $n_0$ in un intervallo di tempo, e che tale numero di eventi pu\`{o} essere distinto in due sotto categorie date da $n_s$ che \`{e} il numero di eventi dovuto a un processo fisico e $n_b$ numero di eventi che definiscono il "rumore di fondo" ( e rappresenta fenomeni non legati al processo fisico osservato) dove $n_0 = n_s + n_b$. A priori non abbiamo modo di sapere nel conteggio quanti fenomeni fisici e non compongano $n_0$. In compenso conosciamo il numero medio di eventi di entrambi i conteggi $E[n_s] = \nu_s$ e $E[n_b] = \nu_b$. \newline
Costruiamo la nostra null hypothesis $H_0$ assumendo che del numero complessivo di fenomeni buona parte siano dati dal rumore di fondo; per confutare tale ipotesi utilizzando il p-value \`{e} necessario che questo sia pi\`{u} piccolo del valore di soglia $p_0$, in fisica delle particelle si sceglie $p_0 = 3 \times 10^-7$ per il segnale che una particella sia stata rilevata. La Poissoniana che  descrive la probabilit\`{a} di $n_b$ \`{e} data da:
\begin{equation*}
	Poiss(n_b,\nu_b) = \dfrac{\nu^n}{n!}e^{-\nu}
\end{equation*} 

\noindent la probabilit\`{a} di misurare un valore $n_b$ di quello misurato \`{e} data da:
\begin{equation}
	\beta = P(n > n_b^{0}) = \sum_{k =n_0+1}^{\infty}\dfrac{\nu^k}{k!}e^{-\nu} = 1- \sum_{k =0}^{n}\dfrac{\nu^k}{k!}e^{-\nu}  	
\end{equation}
Possiamo riscrivere l'equazione (6.7) come:

\begin{equation}
	1-\beta = \sum_{k =0}^{n}\dfrac{\nu^k}{k!}e^{-\nu} \approx \int_{2n_{b}^0}^{\infty}\chi^2(2n+2)d\chi^2
\end{equation} 
\newline
approssimabile alla distribuzione del $\chi^2(2n+2)$ con 2(n+1) g.d.l., ovvero l'espressione di sinistra della 6.8 coincide con la sua c.d.f. Di conseguenza avremo che il:
\begin{equation*}
	\text{p-value} = 1- \beta
\end{equation*}
Per $\beta \approx 1$ il p-value \`{e} molto piccolo e quindi possiamo rigettare la null hypothesis $H_0$ formulata all'inizio e quindi il segnale osservato \`{e} effettivamente un processo fisico. Un valore grande di $\beta$ ci dice che si ha un alta probabilit\`{a} che per valori pi\`{u} grandi di $n_b^0$ i fenomeni osservati siano composti per la maggior parte da rumore di fondo. Mentre per $1-\beta$ molto piccolo si ha una bassa probabilit\`{a} che quanto osservato sia dato da rumore di fondo.

\end{document}